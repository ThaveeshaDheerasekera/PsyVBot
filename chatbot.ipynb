{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:44.844590Z",
     "end_time": "2023-04-13T02:17:44.848347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:45.972174Z",
     "end_time": "2023-04-13T02:17:45.977884Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Define word2index dictionary (replace with your own)\n",
    "word2index = {\n",
    "    \"<PAD>\": 0,\n",
    "    \"<UNK>\": 1,\n",
    "    \"hello\": 2,\n",
    "    \"world\": 3,\n",
    "    \"how\": 4,\n",
    "    \"are\": 5,\n",
    "    \"you\": 6,\n",
    "    \"today\": 7,\n",
    "    \"i\": 8,\n",
    "    \"am\": 9,\n",
    "    \"doing\": 10,\n",
    "    \"fine\": 11,\n",
    "    \"thank\": 12\n",
    "}\n",
    "index2word = {index: word for word, index in word2index.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:46.551484Z",
     "end_time": "2023-04-13T02:17:46.553876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Load Cornell Movie Dialogs Corpus\n",
    "path_to_movie_lines = \"datasets/cornell_movie_dialogs_corpus/movie_lines.txt\"\n",
    "path_to_movie_conversations = \"datasets/cornell_movie_dialogs_corpus/movie_conversations.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:47.146816Z",
     "end_time": "2023-04-13T02:17:47.149555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# Create a dictionary to map line ids to their corresponding text\n",
    "id2line = {}\n",
    "with io.open(path_to_movie_lines, 'r', encoding='iso-8859-1') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    parts = line.strip().split(' +++$+++ ')\n",
    "    if len(parts) >= 5:\n",
    "        id2line[parts[0]] = parts[4]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:47.580590Z",
     "end_time": "2023-04-13T02:17:47.853388Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Create a list of all conversations\n",
    "conversations = []\n",
    "with open(path_to_movie_conversations, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    parts = line.strip().split(' +++$+++ ')\n",
    "    # Convert string representation of list to actual list\n",
    "    convo = list(eval(parts[3]))\n",
    "    convo_text = []\n",
    "    for utt_id in convo:\n",
    "        if utt_id in id2line:\n",
    "            convo_text.append(id2line[utt_id])\n",
    "    if len(convo_text) > 1:\n",
    "        conversations.append(convo_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:48.586386Z",
     "end_time": "2023-04-13T02:17:49.763963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load saved lstm model\n",
    "path_to_lstm_model = \"models/final_models/lstm_e10_b32.h5\"\n",
    "lstm_model = tf.keras.models.load_model(path_to_lstm_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:42.783907Z",
     "end_time": "2023-04-13T02:17:43.184885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Define function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"[-()\\\";:<>{}+=~.,|?!]\", \"\", text)\n",
    "    text = text.strip()\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:17:43.188257Z",
     "end_time": "2023-04-13T02:17:43.190606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Define function to generate responses\n",
    "def generate_response(input_text, max_len, user_inputs):\n",
    "    # Preprocess input text\n",
    "    input_text = preprocess_text(input_text)\n",
    "    # Convert input text to sequence of integers\n",
    "    input_seq = []\n",
    "    for word in input_text.split():\n",
    "        if word in word2index:\n",
    "            input_seq.append(word2index[word])\n",
    "        else:\n",
    "            input_seq.append(word2index[\"<UNK>\"])\n",
    "    input_seq = np.array(input_seq)\n",
    "    # Use LSTM model to generate response\n",
    "    response_seq = []\n",
    "    # Initialize state to None\n",
    "    state = None\n",
    "    for i in range(max_len):\n",
    "        # Generate output for one time step\n",
    "        output, state = lstm_model.predict([np.expand_dims(input_seq, axis=0), state])\n",
    "        # Get most likely next word\n",
    "        next_word = np.argmax(output[0, i, :])\n",
    "        if index2word[next_word] == \"<EOS>\":\n",
    "            break\n",
    "        response_seq.append(next_word)\n",
    "    # Convert sequence of integers to text\n",
    "    response_text = \"\"\n",
    "    for index in response_seq:\n",
    "        if index2word[index] != \"<PAD>\":\n",
    "            response_text += index2word[index] + \" \"\n",
    "    # Save user input and generated response\n",
    "    user_inputs.append(input_text)\n",
    "    user_inputs.append(response_text)\n",
    "    # Check if user has provided enough input to diagnose depression\n",
    "    if len(user_inputs) < 20:\n",
    "        return \"not enough input to diagnose\"\n",
    "    # Preprocess user input\n",
    "    user_input_seq = []\n",
    "    for user_input in user_inputs:\n",
    "        user_input = preprocess_text(user_input)\n",
    "        for word in user_input.split():\n",
    "            if word in word2index:\n",
    "                user_input_seq.append(word2index[word])\n",
    "            else:\n",
    "                user_input_seq.append(word2index[\"<UNK>\"])\n",
    "    user_input_seq = np.array(user_input_seq)\n",
    "    # Use LSTM model to predict depression diagnosis\n",
    "    predicted_output = lstm_model.predict(np.expand_dims(user_input_seq, axis=0))\n",
    "    if predicted_output > 0.5:\n",
    "        return \"You might be showing signs of depression. Please seek professional help.\"\n",
    "    else:\n",
    "        return \"You seem to be doing well. Keep it up!\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T02:53:10.302822Z",
     "end_time": "2023-04-13T02:53:10.305857Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\", \"<class 'NoneType'>\"}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Generate response\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Print response\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChatbot:\u001B[39m\u001B[38;5;124m\"\u001B[39m, response)\n",
      "Cell \u001B[0;32mIn[58], line 19\u001B[0m, in \u001B[0;36mgenerate_response\u001B[0;34m(input_text, max_len, user_inputs)\u001B[0m\n\u001B[1;32m     16\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_len):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# Generate output for one time step\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m     output, state \u001B[38;5;241m=\u001B[39m \u001B[43mlstm_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;66;03m# Get most likely next word\u001B[39;00m\n\u001B[1;32m     21\u001B[0m     next_word \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(output[\u001B[38;5;241m0\u001B[39m, i, :])\n",
      "File \u001B[0;32m~/Developer/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Developer/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/data_adapter.py:1082\u001B[0m, in \u001B[0;36mselect_data_adapter\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m   1079\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mcls\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m ALL_ADAPTER_CLS \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mcan_handle(x, y)]\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m adapter_cls:\n\u001B[1;32m   1081\u001B[0m     \u001B[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001B[39;00m\n\u001B[0;32m-> 1082\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1083\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to find data adapter that can handle input: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1084\u001B[0m             _type_name(x), _type_name(y)\n\u001B[1;32m   1085\u001B[0m         )\n\u001B[1;32m   1086\u001B[0m     )\n\u001B[1;32m   1087\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(adapter_cls) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1089\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData adapters should be mutually exclusive for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1090\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandling inputs. Found multiple adapters \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m to handle \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1091\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001B[1;32m   1092\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\", \"<class 'NoneType'>\"}), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Define user inputs list\n",
    "user_inputs = []\n",
    "\n",
    "# Define max sequence length\n",
    "max_len = 20\n",
    "\n",
    "# Start conversation with user\n",
    "print(\"Hello! How can I help you today?\")\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # Check if user wants to end the conversation\n",
    "    if user_input.lower() == \"bye\":\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Check if user wants to diagnose depression\n",
    "    if user_input.lower() == \"diagnose\":\n",
    "        # Generate response\n",
    "        response = generate_response(\"diagnose\", max_len, user_inputs)\n",
    "\n",
    "        # Print response\n",
    "        print(\"Chatbot:\", response)\n",
    "        continue\n",
    "\n",
    "    # Add user input to list\n",
    "    user_inputs.append(user_input)\n",
    "\n",
    "    # Continue conversation\n",
    "    print(\"Chatbot: How else can I help you?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.10 (tensorflow)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
